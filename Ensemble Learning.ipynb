{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "import optuna\n",
    "import ray\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    balanced_accuracy_score,\n",
    ")\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, SMOTENC\n",
    "from sklearn.utils import compute_class_weight, class_weight\n",
    "from sklearn.manifold import Isomap\n",
    "from typing import Tuple\n",
    "from scipy.special import expit\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train['EJ'].replace(['A', 'B'], [1, 0], inplace=True)\n",
    "\n",
    "ej = np.array(train['EJ']).reshape(-1, 1)\n",
    "\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "y = train['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "x_numerical_columns = train.drop(columns=[\"Id\", \"Class\", \"EJ\"]).columns.tolist()\n",
    "x_categorical_columns = [\"EJ\"]\n",
    "x_cols = x_numerical_columns + x_categorical_columns\n",
    "\n",
    "scaler.fit(train[x_numerical_columns])\n",
    "\n",
    "X = scaler.transform(train[x_numerical_columns])\n",
    "X = np.concatenate((X, ej), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "knn = KNNImputer()\n",
    "knn.fit(X)\n",
    "\n",
    "X = knn.fit_transform(X)\n",
    "\n",
    "X = pd.DataFrame(X, columns=x_cols)\n",
    "X['EJ'] = X['EJ'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_df = X[X>10].dropna(how='all').dropna(how='all', axis=1)\n",
    "\n",
    "outlier_index = outlier_df.loc[(y==0)].index.tolist()\n",
    "\n",
    "X = X.drop(index=outlier_index).reset_index(drop=True)\n",
    "y = y.drop(index=outlier_index).reset_index(drop=True)\n",
    "\n",
    "X['EJ'] = X['EJ'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancedlogloss_lgb(\n",
    "    predt: np.ndarray, dtrain: lgb.Dataset\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    y = dtrain.get_label()\n",
    "    n0 = len(y[y == 0])\n",
    "    n1 = len(y[y == 1])\n",
    "\n",
    "    p = expit(predt)\n",
    "    p[p == 0] = 1e-15\n",
    "\n",
    "    grad = 1 / 2 * ((1 - y) / (1 - p) - y / p)\n",
    "    hess = 1 / 2 * ((1 - y) / ((1 - p) ** 2) + y / (p**2))\n",
    "    return grad, hess\n",
    "\n",
    "def balancedlogloss_xgb(\n",
    "    predt: np.ndarray, dtrain: xgb.DMatrix\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    y = dtrain.get_label()\n",
    "    n0 = len(y[y == 0])\n",
    "    n1 = len(y[y == 1])\n",
    "\n",
    "    p = expit(predt)\n",
    "    p[p == 0] = 1e-15\n",
    "\n",
    "    grad = 1 / 2 * ((1 - y) / (1 - p) - y / p)\n",
    "    hess = 1 / 2 * ((1 - y) / ((1 - p) ** 2) + y / (p**2))\n",
    "    return grad, hess\n",
    "\n",
    "\n",
    "def balancedlogloss_eval_lgb(\n",
    "    predt: np.ndarray, dtrain: lgb.Dataset\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    y = dtrain.get_label()\n",
    "    n0 = len(y[y == 0])\n",
    "    n1 = len(y[y == 1])\n",
    "    p = expit(predt)\n",
    "\n",
    "    p[p == 0] = 1e-15\n",
    "\n",
    "    return (\n",
    "        \"balanced_logloss\",\n",
    "        (-1/ n0 * (sum((1 - y) * np.log(1 - p))) - 1 / n1 * (sum(y * np.log(p)))) / 2,\n",
    "        True\n",
    "    )\n",
    "\n",
    "def balancedlogloss_eval_xgb(\n",
    "    predt: np.ndarray, dtrain: lgb.Dataset\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    y = dtrain.get_label()\n",
    "    n0 = len(y[y == 0])\n",
    "    n1 = len(y[y == 1])\n",
    "    p = expit(predt)\n",
    "\n",
    "    p[p == 0] = 1e-15\n",
    "\n",
    "    return (\n",
    "        \"balanced_logloss\",\n",
    "        (-1 / n0 * (sum((1 - y) * np.log(1 - p))) - 1 / n1 * (sum(y * np.log(p)))) / 2,\n",
    "    )\n",
    "\n",
    "def score(p, y):\n",
    "\n",
    "    p[p == 0] = 1e-15\n",
    "\n",
    "    n0 = len(y[y == 0])\n",
    "    n1 = len(y[y == 1])\n",
    "\n",
    "    return ((-1/ n0 * (sum((1 - y) * np.log(1 - p))) - 1 / n1 * (sum(y * np.log(p)))) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3096564452571329\n",
      "0.31057634226937636\n",
      "ensemble: 0.30338087580102013\n",
      "0.20383397251020607\n",
      "0.2912837465944597\n",
      "ensemble: 0.26670834535559107\n",
      "0.6507522183350449\n",
      "0.5591894967631519\n",
      "ensemble: 0.5673677473887737\n",
      "0.3727705369303955\n",
      "0.3926642610816981\n",
      "ensemble: 0.3743143587696942\n",
      "0.24973399436065502\n",
      "0.2968230423919521\n",
      "ensemble: 0.27860853720592443\n",
      "0.32579044541968405\n",
      "0.363046008196092\n",
      "ensemble: 0.33704108449138326\n",
      "0.36896261013422677\n",
      "0.42879258318588936\n",
      "ensemble: 0.4051230795805713\n",
      "0.2725259485264542\n",
      "0.34308169547875805\n",
      "ensemble: 0.31128519731407334\n",
      "0.6179906908684624\n",
      "0.4350784191365407\n",
      "ensemble: 0.41010973831498543\n",
      "0.432512374738088\n",
      "0.3649735542230159\n",
      "ensemble: 0.361292164309839\n",
      "\n",
      "\n",
      "xgb: 0.38045292370803496\n",
      "lgb: 0.3785509149320935\n",
      "ensemble:0.3615231128531856\n"
     ]
    }
   ],
   "source": [
    "xgb_param = {'learning_rate': 0.05,\n",
    "             'subsample': 0.7,\n",
    "             'lambda': 40,\n",
    "             'gamma': 20,\n",
    "             'disable_default_eval_metric': True}\n",
    "\n",
    "lgb_param = {'learning_rate': 0.05,\n",
    "             'lambda_l1': 40,\n",
    "             'lambda_l2': 10,\n",
    "             'subsample': 0.7,\n",
    "             'verbosity': -1,\n",
    "             'colsample_bytree': 0.8,\n",
    "             }\n",
    "\n",
    "kf = KFold(10)\n",
    "cols = X.columns.tolist()\n",
    "\n",
    "df_xgb_train, df_xgb_test = pd.DataFrame(), pd.DataFrame()\n",
    "df_lgb_train, df_lgb_test = pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "xgb_scores = []\n",
    "lgb_scores = []\n",
    "scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "\n",
    "    # sampler = RandomOverSampler()\n",
    "    sampler = SMOTE()\n",
    "    X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "    evals_xgb = {}\n",
    "    dtrain_xgb = xgb.DMatrix(X_train, y_train, feature_names=cols, enable_categorical=True)\n",
    "    dtest_xgb = xgb.DMatrix(X_test, y_test, feature_names=cols, enable_categorical=True)\n",
    "    xgb_model = xgb.train(params=xgb_param,\n",
    "                          dtrain=dtrain_xgb,\n",
    "                          obj=balancedlogloss_xgb,\n",
    "                          verbose_eval=False,\n",
    "                          evals=[(dtrain_xgb, 'train'), (dtest_xgb, 'test')],\n",
    "                          feval=balancedlogloss_eval_xgb,\n",
    "                          evals_result=evals_xgb,\n",
    "                          num_boost_round=500,\n",
    "                        #   early_stopping_rounds=20,\n",
    "                          )\n",
    "    \n",
    "    df_xgb_train = pd.concat([df_xgb_train, pd.Series(evals_xgb['train']['balanced_logloss'])], axis=1)\n",
    "    df_xgb_test = pd.concat([df_xgb_test, pd.Series(evals_xgb['test']['balanced_logloss'])], axis=1)\n",
    "\n",
    "    xgb_train_preds = expit(xgb_model.predict(dtrain_xgb, output_margin=True))\n",
    "    xgb_test_preds = expit(xgb_model.predict(dtest_xgb, output_margin=True))\n",
    "\n",
    "    xgb_score = score(xgb_test_preds, y_test)\n",
    "    xgb_scores = xgb_scores + [xgb_score]\n",
    "    print(xgb_score)\n",
    "\n",
    "    evals_lgb = {}\n",
    "    dtrain_lgb = lgb.Dataset(X_train, y_train)\n",
    "    dtest_lgb = lgb.Dataset(X_test, y_test)\n",
    "    lgb_model = lgb.train(params=lgb_param,\n",
    "                          train_set=dtrain_lgb,\n",
    "                          valid_sets=[dtrain_lgb, dtest_lgb],\n",
    "                          fobj=balancedlogloss_lgb,\n",
    "                          feval=balancedlogloss_eval_lgb,\n",
    "                          evals_result=evals_lgb,\n",
    "                          valid_names=['train', 'test'],\n",
    "                          num_boost_round=150,\n",
    "                          verbose_eval=False)\n",
    "\n",
    "    df_lgb_train = pd.concat([df_lgb_train, pd.Series(evals_lgb['train']['balanced_logloss'])], axis=1)\n",
    "    df_lgb_test = pd.concat([df_lgb_test, pd.Series(evals_lgb['test']['balanced_logloss'])], axis=1)\n",
    "\n",
    "    lgb_train_preds = expit(lgb_model.predict(X_train, raw_score=True))\n",
    "    lgb_test_preds = expit(lgb_model.predict(X_test, raw_score=True))\n",
    "\n",
    "    lgb_score = score(lgb_test_preds, y_test)\n",
    "    lgb_scores = lgb_scores + [lgb_score]\n",
    "    print(lgb_score)\n",
    "\n",
    "    stacked_preds_train = np.column_stack((xgb_train_preds, lgb_train_preds))\n",
    "    stacked_preds_test = np.column_stack((xgb_test_preds, lgb_test_preds))\n",
    "\n",
    "    meta_model = LogisticRegression(C=2.0)\n",
    "    meta_model.fit(stacked_preds_train, y_train)\n",
    "\n",
    "    coefs = [i/np.sum(meta_model.coef_[0]) for i in meta_model.coef_[0]]\n",
    "    ensemble_preds = coefs[0]*xgb_test_preds + coefs[1]*lgb_test_preds\n",
    "\n",
    "    test_score = score(ensemble_preds, np.array(y_test))\n",
    "    scores = scores + [test_score]\n",
    "    print('ensemble: ' + str(test_score))\n",
    "\n",
    "df_xgb = pd.DataFrame()\n",
    "df_xgb['train'] = df_xgb_train.mean(axis=1)\n",
    "df_xgb['test'] = df_xgb_test.mean(axis=1)\n",
    "\n",
    "df_lgb = pd.DataFrame()\n",
    "df_lgb['train'] = df_lgb_train.mean(axis=1)\n",
    "df_lgb['test'] = df_lgb_test.mean(axis=1)\n",
    "\n",
    "print('\\n')\n",
    "print('xgb: ' + str(np.mean(xgb_scores)))\n",
    "print('lgb: ' + str(np.mean(lgb_scores)))\n",
    "print('ensemble:' + str(np.mean(scores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
