{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "import optuna\n",
    "import ray\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    balanced_accuracy_score,\n",
    ")\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, SMOTENC\n",
    "from sklearn.utils import compute_class_weight, class_weight\n",
    "from sklearn.manifold import Isomap\n",
    "from typing import Tuple\n",
    "from scipy.special import expit\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.manifold import Isomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train['EJ'].replace(['A', 'B'], [1, 0], inplace=True)\n",
    "\n",
    "ej = np.array(train['EJ']).reshape(-1, 1)\n",
    "\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "y = train['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "x_numerical_columns = train.drop(columns=[\"Id\", \"Class\", \"EJ\"]).columns.tolist()\n",
    "x_categorical_columns = [\"EJ\"]\n",
    "x_cols = x_numerical_columns + x_categorical_columns\n",
    "\n",
    "scaler.fit(train[x_numerical_columns])\n",
    "\n",
    "X = scaler.transform(train[x_numerical_columns])\n",
    "X = np.concatenate((X, ej), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "knn = KNNImputer()\n",
    "knn.fit(X)\n",
    "\n",
    "X = knn.fit_transform(X)\n",
    "\n",
    "X = pd.DataFrame(X, columns=x_cols)\n",
    "X['EJ'] = X['EJ'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_df = X[X>10].dropna(how='all').dropna(how='all', axis=1)\n",
    "\n",
    "outlier_index = outlier_df.loc[(y==0)].index.tolist()\n",
    "\n",
    "X = X.drop(index=outlier_index).reset_index(drop=True)\n",
    "y = y.drop(index=outlier_index).reset_index(drop=True)\n",
    "\n",
    "X['EJ'] = X['EJ'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancedlogloss_lgb(\n",
    "    predt: np.ndarray, dtrain: lgb.Dataset\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    y = dtrain.get_label()\n",
    "    n0 = len(y[y == 0])\n",
    "    n1 = len(y[y == 1])\n",
    "\n",
    "    p = expit(predt)\n",
    "    p[p == 0] = 1e-15\n",
    "\n",
    "    grad = 1 / 2 * ((1 - y) / (1 - p) - y / p)\n",
    "    hess = 1 / 2 * ((1 - y) / ((1 - p) ** 2) + y / (p**2))\n",
    "    return grad, hess\n",
    "\n",
    "def balancedlogloss_xgb(\n",
    "    predt: np.ndarray, dtrain: xgb.DMatrix\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    y = dtrain.get_label()\n",
    "    n0 = len(y[y == 0])\n",
    "    n1 = len(y[y == 1])\n",
    "\n",
    "    p = expit(predt)\n",
    "    p[p == 0] = 1e-15\n",
    "\n",
    "    grad = 1 / 2 * ((1 - y) / (1 - p) - y / p)\n",
    "    hess = 1 / 2 * ((1 - y) / ((1 - p) ** 2) + y / (p**2))\n",
    "    return grad, hess\n",
    "\n",
    "\n",
    "def balancedlogloss_eval_lgb(\n",
    "    predt: np.ndarray, dtrain: lgb.Dataset\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    y = dtrain.get_label()\n",
    "    n0 = len(y[y == 0])\n",
    "    n1 = len(y[y == 1])\n",
    "    p = expit(predt)\n",
    "\n",
    "    p[p == 0] = 1e-15\n",
    "\n",
    "    return (\n",
    "        \"balanced_logloss\",\n",
    "        (-1/ n0 * (sum((1 - y) * np.log(1 - p))) - 1 / n1 * (sum(y * np.log(p)))) / 2,\n",
    "        True\n",
    "    )\n",
    "\n",
    "def balancedlogloss_eval_xgb(\n",
    "    predt: np.ndarray, dtrain: lgb.Dataset\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    y = dtrain.get_label()\n",
    "    n0 = len(y[y == 0])\n",
    "    n1 = len(y[y == 1])\n",
    "    p = expit(predt)\n",
    "\n",
    "    p[p == 0] = 1e-15\n",
    "\n",
    "    return (\n",
    "        \"balanced_logloss\",\n",
    "        (-1 / n0 * (sum((1 - y) * np.log(1 - p))) - 1 / n1 * (sum(y * np.log(p)))) / 2,\n",
    "    )\n",
    "\n",
    "def score(p, y):\n",
    "\n",
    "    p[p == 0] = 1e-15\n",
    "\n",
    "    n0 = len(y[y == 0])\n",
    "    n1 = len(y[y == 1])\n",
    "\n",
    "    return ((-1/ n0 * (sum((1 - y) * np.log(1 - p))) - 1 / n1 * (sum(y * np.log(p)))) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trials_df(trials_dataframe):\n",
    "    col_index = [1] + [i for i in range(5, trials_dataframe.shape[1]-1)]\n",
    "\n",
    "    trials_dataframe = trials_dataframe.iloc[:, col_index]\n",
    "    trials_dataframe = trials_dataframe.groupby(trials_dataframe.columns.tolist()[1:]).mean()\n",
    "\n",
    "    trials_dataframe = trials_dataframe.sort_values(by=['value'], ascending=True)\n",
    "\n",
    "    return trials_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-27 18:46:39,907] A new study created in memory with name: no-name-3f6572b1-73d0-4da1-9db7-c7cf059c44e8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-27 18:47:10,384] Trial 0 finished with value: 0.3087522021265533 and parameters: {'min_child_weight': 12, 'reg_lambda': 0.5, 'reg_alpha': 3.5, 'max_depth': 12, 'subsample': 0.5, 'colsample_bytree': 0.18}. Best is trial 0 with value: 0.3087522021265533.\n",
      "[I 2023-06-27 18:47:47,458] Trial 1 finished with value: 0.29147330770715824 and parameters: {'min_child_weight': 13, 'reg_lambda': 0.95, 'reg_alpha': 3.8, 'max_depth': 8, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.1}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 18:48:23,893] Trial 2 finished with value: 0.33138281434556804 and parameters: {'min_child_weight': 14, 'reg_lambda': 0.8500000000000001, 'reg_alpha': 4.3, 'max_depth': 8, 'subsample': 0.2, 'colsample_bytree': 0.08}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 18:48:58,600] Trial 3 finished with value: 0.3494696876679245 and parameters: {'min_child_weight': 13, 'reg_lambda': 0.9000000000000001, 'reg_alpha': 4.1, 'max_depth': 8, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.1}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 18:49:36,677] Trial 4 finished with value: 0.3271881140481843 and parameters: {'min_child_weight': 8, 'reg_lambda': 0.4, 'reg_alpha': 3.7, 'max_depth': 8, 'subsample': 0.4, 'colsample_bytree': 0.1}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 18:50:13,899] Trial 5 finished with value: 0.35576487227695 and parameters: {'min_child_weight': 8, 'reg_lambda': 0.45, 'reg_alpha': 4.0, 'max_depth': 12, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.2}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 18:50:58,802] Trial 6 finished with value: 0.3290070793882525 and parameters: {'min_child_weight': 14, 'reg_lambda': 0.35, 'reg_alpha': 3.7, 'max_depth': 10, 'subsample': 0.5, 'colsample_bytree': 0.08}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 18:51:42,101] Trial 7 finished with value: 0.3245035855778875 and parameters: {'min_child_weight': 10, 'reg_lambda': 0.75, 'reg_alpha': 3.6, 'max_depth': 12, 'subsample': 0.2, 'colsample_bytree': 0.18}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 18:52:24,107] Trial 8 finished with value: 0.3380821762611367 and parameters: {'min_child_weight': 8, 'reg_lambda': 0.6000000000000001, 'reg_alpha': 4.1, 'max_depth': 8, 'subsample': 0.5, 'colsample_bytree': 0.1}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 18:53:16,821] Trial 9 finished with value: 0.3353395079010748 and parameters: {'min_child_weight': 13, 'reg_lambda': 0.9000000000000001, 'reg_alpha': 3.6, 'max_depth': 12, 'subsample': 0.4, 'colsample_bytree': 0.08}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 18:53:57,553] Trial 10 pruned. \n",
      "[I 2023-06-27 18:54:26,988] Trial 11 finished with value: 0.3196511234543042 and parameters: {'min_child_weight': 12, 'reg_lambda': 0.6000000000000001, 'reg_alpha': 3.9, 'max_depth': 12, 'subsample': 0.7, 'colsample_bytree': 0.18}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 18:54:57,629] Trial 12 pruned. \n",
      "[I 2023-06-27 18:55:28,600] Trial 13 finished with value: 0.32494822866243717 and parameters: {'min_child_weight': 12, 'reg_lambda': 0.7, 'reg_alpha': 3.8, 'max_depth': 8, 'subsample': 0.4, 'colsample_bytree': 0.12}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 18:55:58,572] Trial 14 pruned. \n",
      "[I 2023-06-27 18:56:30,672] Trial 15 finished with value: 0.3374752999500577 and parameters: {'min_child_weight': 13, 'reg_lambda': 0.5, 'reg_alpha': 3.8, 'max_depth': 8, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.1}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 18:57:04,244] Trial 16 finished with value: 0.3339324867228411 and parameters: {'min_child_weight': 11, 'reg_lambda': 1.0, 'reg_alpha': 3.9, 'max_depth': 12, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.18}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 18:57:37,368] Trial 17 finished with value: 0.36176110666197914 and parameters: {'min_child_weight': 9, 'reg_lambda': 0.8, 'reg_alpha': 3.5, 'max_depth': 8, 'subsample': 0.7, 'colsample_bytree': 0.1}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 18:58:07,638] Trial 18 finished with value: 0.3416458283677739 and parameters: {'min_child_weight': 10, 'reg_lambda': 0.6000000000000001, 'reg_alpha': 3.7, 'max_depth': 12, 'subsample': 0.5, 'colsample_bytree': 0.18}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 18:58:38,340] Trial 19 finished with value: 0.292010290545388 and parameters: {'min_child_weight': 12, 'reg_lambda': 0.65, 'reg_alpha': 4.3, 'max_depth': 10, 'subsample': 0.2, 'colsample_bytree': 0.12}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 18:59:18,820] Trial 20 finished with value: 0.2962522397232632 and parameters: {'min_child_weight': 13, 'reg_lambda': 0.7, 'reg_alpha': 4.3, 'max_depth': 10, 'subsample': 0.2, 'colsample_bytree': 0.12}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 18:59:58,890] Trial 21 finished with value: 0.31352573390238414 and parameters: {'min_child_weight': 13, 'reg_lambda': 0.7, 'reg_alpha': 4.3, 'max_depth': 10, 'subsample': 0.2, 'colsample_bytree': 0.12}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:00:40,420] Trial 22 finished with value: 0.3126372477423874 and parameters: {'min_child_weight': 13, 'reg_lambda': 0.65, 'reg_alpha': 4.4, 'max_depth': 10, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.12}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:01:22,966] Trial 23 finished with value: 0.3341070338065552 and parameters: {'min_child_weight': 13, 'reg_lambda': 0.8, 'reg_alpha': 4.2, 'max_depth': 10, 'subsample': 0.2, 'colsample_bytree': 0.12}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:02:01,561] Trial 24 finished with value: 0.3030323816111802 and parameters: {'min_child_weight': 13, 'reg_lambda': 0.95, 'reg_alpha': 4.5, 'max_depth': 10, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.12}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:02:40,607] Trial 25 finished with value: 0.3140595962078363 and parameters: {'min_child_weight': 12, 'reg_lambda': 0.7, 'reg_alpha': 4.3, 'max_depth': 10, 'subsample': 0.2, 'colsample_bytree': 0.12}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:03:21,511] Trial 26 finished with value: 0.29466158157598243 and parameters: {'min_child_weight': 13, 'reg_lambda': 0.8, 'reg_alpha': 4.2, 'max_depth': 10, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.12}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:03:55,318] Trial 27 pruned. \n",
      "[I 2023-06-27 19:04:25,641] Trial 28 finished with value: 0.30688163905505084 and parameters: {'min_child_weight': 11, 'reg_lambda': 0.8, 'reg_alpha': 4.0, 'max_depth': 10, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.1}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:04:55,124] Trial 29 finished with value: 0.317169523457823 and parameters: {'min_child_weight': 12, 'reg_lambda': 0.9000000000000001, 'reg_alpha': 4.2, 'max_depth': 8, 'subsample': 0.4, 'colsample_bytree': 0.12}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:05:25,577] Trial 30 finished with value: 0.32024823910024747 and parameters: {'min_child_weight': 14, 'reg_lambda': 0.95, 'reg_alpha': 4.4, 'max_depth': 10, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.12}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:05:57,293] Trial 31 finished with value: 0.30929886384526045 and parameters: {'min_child_weight': 13, 'reg_lambda': 0.65, 'reg_alpha': 4.2, 'max_depth': 10, 'subsample': 0.2, 'colsample_bytree': 0.12}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:06:28,460] Trial 32 finished with value: 0.31801280041229696 and parameters: {'min_child_weight': 13, 'reg_lambda': 0.75, 'reg_alpha': 4.4, 'max_depth': 10, 'subsample': 0.2, 'colsample_bytree': 0.12}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:06:58,561] Trial 33 finished with value: 0.3153744725679977 and parameters: {'min_child_weight': 13, 'reg_lambda': 0.55, 'reg_alpha': 4.3, 'max_depth': 10, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.12}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:07:31,507] Trial 34 finished with value: 0.331205842301618 and parameters: {'min_child_weight': 13, 'reg_lambda': 0.75, 'reg_alpha': 4.1, 'max_depth': 8, 'subsample': 0.2, 'colsample_bytree': 0.08}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:08:00,841] Trial 35 finished with value: 0.3290685639336389 and parameters: {'min_child_weight': 10, 'reg_lambda': 0.8500000000000001, 'reg_alpha': 4.2, 'max_depth': 10, 'subsample': 0.4, 'colsample_bytree': 0.1}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:08:28,756] Trial 36 finished with value: 0.3100968818138355 and parameters: {'min_child_weight': 14, 'reg_lambda': 0.55, 'reg_alpha': 4.3, 'max_depth': 8, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.12}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:08:56,634] Trial 37 finished with value: 0.30417867180065095 and parameters: {'min_child_weight': 8, 'reg_lambda': 0.8500000000000001, 'reg_alpha': 4.4, 'max_depth': 10, 'subsample': 0.2, 'colsample_bytree': 0.2}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:09:30,156] Trial 38 finished with value: 0.2972682492599957 and parameters: {'min_child_weight': 13, 'reg_lambda': 0.7, 'reg_alpha': 4.0, 'max_depth': 8, 'subsample': 0.4, 'colsample_bytree': 0.1}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:10:04,541] Trial 39 finished with value: 0.3400645818221014 and parameters: {'min_child_weight': 12, 'reg_lambda': 0.95, 'reg_alpha': 3.9, 'max_depth': 10, 'subsample': 0.5, 'colsample_bytree': 0.08}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:10:39,169] Trial 40 finished with value: 0.31257088016749024 and parameters: {'min_child_weight': 13, 'reg_lambda': 0.75, 'reg_alpha': 4.1, 'max_depth': 10, 'subsample': 0.2, 'colsample_bytree': 0.1}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:11:11,676] Trial 41 finished with value: 0.31285877967176556 and parameters: {'min_child_weight': 13, 'reg_lambda': 0.65, 'reg_alpha': 3.8, 'max_depth': 8, 'subsample': 0.4, 'colsample_bytree': 0.1}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:11:46,826] Trial 42 finished with value: 0.3255085072027632 and parameters: {'min_child_weight': 13, 'reg_lambda': 0.7, 'reg_alpha': 4.0, 'max_depth': 8, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.1}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:12:19,561] Trial 43 finished with value: 0.3314022252527723 and parameters: {'min_child_weight': 13, 'reg_lambda': 0.55, 'reg_alpha': 4.0, 'max_depth': 8, 'subsample': 0.5, 'colsample_bytree': 0.1}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:12:53,977] Trial 44 finished with value: 0.3260866212507864 and parameters: {'min_child_weight': 8, 'reg_lambda': 0.6000000000000001, 'reg_alpha': 4.2, 'max_depth': 8, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.1}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:13:28,880] Trial 45 finished with value: 0.34048696742621176 and parameters: {'min_child_weight': 13, 'reg_lambda': 0.8, 'reg_alpha': 3.9, 'max_depth': 8, 'subsample': 0.4, 'colsample_bytree': 0.12}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:14:03,537] Trial 46 finished with value: 0.32323355245989144 and parameters: {'min_child_weight': 10, 'reg_lambda': 0.7, 'reg_alpha': 4.3, 'max_depth': 8, 'subsample': 0.2, 'colsample_bytree': 0.08}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:14:34,011] Trial 47 finished with value: 0.31442218381663967 and parameters: {'min_child_weight': 12, 'reg_lambda': 0.9000000000000001, 'reg_alpha': 3.6, 'max_depth': 8, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.1}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:14:58,822] Trial 48 finished with value: 0.3011100618382179 and parameters: {'min_child_weight': 14, 'reg_lambda': 0.65, 'reg_alpha': 4.1, 'max_depth': 12, 'subsample': 0.7, 'colsample_bytree': 0.2}. Best is trial 1 with value: 0.29147330770715824.\n",
      "[I 2023-06-27 19:15:26,104] Trial 49 finished with value: 0.31559099453808936 and parameters: {'min_child_weight': 11, 'reg_lambda': 0.45, 'reg_alpha': 3.7, 'max_depth': 10, 'subsample': 0.4, 'colsample_bytree': 0.12}. Best is trial 1 with value: 0.29147330770715824.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_colsample_bytree</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_min_child_weight</th>\n",
       "      <th>params_reg_alpha</th>\n",
       "      <th>params_reg_lambda</th>\n",
       "      <th>params_subsample</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <th>8</th>\n",
       "      <th>13</th>\n",
       "      <th>3.8</th>\n",
       "      <th>0.95</th>\n",
       "      <th>0.3</th>\n",
       "      <td>0.291473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.12</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th>12</th>\n",
       "      <th>4.3</th>\n",
       "      <th>0.65</th>\n",
       "      <th>0.2</th>\n",
       "      <td>0.292010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <th>4.2</th>\n",
       "      <th>0.80</th>\n",
       "      <th>0.3</th>\n",
       "      <td>0.294662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <th>8</th>\n",
       "      <th>13</th>\n",
       "      <th>4.0</th>\n",
       "      <th>0.70</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.297268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.20</th>\n",
       "      <th>12</th>\n",
       "      <th>14</th>\n",
       "      <th>4.1</th>\n",
       "      <th>0.65</th>\n",
       "      <th>0.7</th>\n",
       "      <td>0.301110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.12</th>\n",
       "      <th>10</th>\n",
       "      <th>13</th>\n",
       "      <th>4.5</th>\n",
       "      <th>0.95</th>\n",
       "      <th>0.3</th>\n",
       "      <td>0.303032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.20</th>\n",
       "      <th>10</th>\n",
       "      <th>8</th>\n",
       "      <th>4.4</th>\n",
       "      <th>0.85</th>\n",
       "      <th>0.2</th>\n",
       "      <td>0.304179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.12</th>\n",
       "      <th>10</th>\n",
       "      <th>13</th>\n",
       "      <th>4.3</th>\n",
       "      <th>0.70</th>\n",
       "      <th>0.2</th>\n",
       "      <td>0.304889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>4.0</th>\n",
       "      <th>0.80</th>\n",
       "      <th>0.3</th>\n",
       "      <td>0.306882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.18</th>\n",
       "      <th>12</th>\n",
       "      <th>12</th>\n",
       "      <th>3.5</th>\n",
       "      <th>0.50</th>\n",
       "      <th>0.5</th>\n",
       "      <td>0.308752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.12</th>\n",
       "      <th>10</th>\n",
       "      <th>13</th>\n",
       "      <th>4.2</th>\n",
       "      <th>0.65</th>\n",
       "      <th>0.2</th>\n",
       "      <td>0.309299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>14</th>\n",
       "      <th>4.3</th>\n",
       "      <th>0.55</th>\n",
       "      <th>0.3</th>\n",
       "      <td>0.310097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <th>10</th>\n",
       "      <th>13</th>\n",
       "      <th>4.1</th>\n",
       "      <th>0.75</th>\n",
       "      <th>0.2</th>\n",
       "      <td>0.312571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.12</th>\n",
       "      <th>10</th>\n",
       "      <th>13</th>\n",
       "      <th>4.4</th>\n",
       "      <th>0.65</th>\n",
       "      <th>0.3</th>\n",
       "      <td>0.312637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <th>8</th>\n",
       "      <th>13</th>\n",
       "      <th>3.8</th>\n",
       "      <th>0.65</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.312859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.12</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>4.3</th>\n",
       "      <th>0.70</th>\n",
       "      <th>0.2</th>\n",
       "      <td>0.314060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <th>8</th>\n",
       "      <th>12</th>\n",
       "      <th>3.6</th>\n",
       "      <th>0.90</th>\n",
       "      <th>0.3</th>\n",
       "      <td>0.314422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.12</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th>13</th>\n",
       "      <th>4.3</th>\n",
       "      <th>0.55</th>\n",
       "      <th>0.3</th>\n",
       "      <td>0.315374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>3.7</th>\n",
       "      <th>0.45</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.315591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>12</th>\n",
       "      <th>4.2</th>\n",
       "      <th>0.90</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.317170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>13</th>\n",
       "      <th>4.4</th>\n",
       "      <th>0.75</th>\n",
       "      <th>0.2</th>\n",
       "      <td>0.318013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.18</th>\n",
       "      <th>12</th>\n",
       "      <th>12</th>\n",
       "      <th>3.9</th>\n",
       "      <th>0.60</th>\n",
       "      <th>0.7</th>\n",
       "      <td>0.319651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.12</th>\n",
       "      <th>10</th>\n",
       "      <th>14</th>\n",
       "      <th>4.4</th>\n",
       "      <th>0.95</th>\n",
       "      <th>0.3</th>\n",
       "      <td>0.320248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.08</th>\n",
       "      <th>8</th>\n",
       "      <th>10</th>\n",
       "      <th>4.3</th>\n",
       "      <th>0.70</th>\n",
       "      <th>0.2</th>\n",
       "      <td>0.323234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.18</th>\n",
       "      <th>12</th>\n",
       "      <th>10</th>\n",
       "      <th>3.6</th>\n",
       "      <th>0.75</th>\n",
       "      <th>0.2</th>\n",
       "      <td>0.324504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.12</th>\n",
       "      <th>8</th>\n",
       "      <th>12</th>\n",
       "      <th>3.8</th>\n",
       "      <th>0.70</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.324948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.10</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">8</th>\n",
       "      <th>13</th>\n",
       "      <th>4.0</th>\n",
       "      <th>0.70</th>\n",
       "      <th>0.3</th>\n",
       "      <td>0.325509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">8</th>\n",
       "      <th>4.2</th>\n",
       "      <th>0.60</th>\n",
       "      <th>0.3</th>\n",
       "      <td>0.326087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.7</th>\n",
       "      <th>0.40</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.327188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.08</th>\n",
       "      <th>10</th>\n",
       "      <th>14</th>\n",
       "      <th>3.7</th>\n",
       "      <th>0.35</th>\n",
       "      <th>0.5</th>\n",
       "      <td>0.329007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <th>10</th>\n",
       "      <th>10</th>\n",
       "      <th>4.2</th>\n",
       "      <th>0.85</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.329069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.08</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">8</th>\n",
       "      <th>13</th>\n",
       "      <th>4.1</th>\n",
       "      <th>0.75</th>\n",
       "      <th>0.2</th>\n",
       "      <td>0.331206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <th>4.3</th>\n",
       "      <th>0.85</th>\n",
       "      <th>0.2</th>\n",
       "      <td>0.331383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <th>8</th>\n",
       "      <th>13</th>\n",
       "      <th>4.0</th>\n",
       "      <th>0.55</th>\n",
       "      <th>0.5</th>\n",
       "      <td>0.331402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.18</th>\n",
       "      <th>12</th>\n",
       "      <th>11</th>\n",
       "      <th>3.9</th>\n",
       "      <th>1.00</th>\n",
       "      <th>0.3</th>\n",
       "      <td>0.333932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.12</th>\n",
       "      <th>10</th>\n",
       "      <th>13</th>\n",
       "      <th>4.2</th>\n",
       "      <th>0.80</th>\n",
       "      <th>0.2</th>\n",
       "      <td>0.334107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.08</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>3.6</th>\n",
       "      <th>0.90</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.335340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.10</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">8</th>\n",
       "      <th>13</th>\n",
       "      <th>3.8</th>\n",
       "      <th>0.50</th>\n",
       "      <th>0.6</th>\n",
       "      <td>0.337475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>4.1</th>\n",
       "      <th>0.60</th>\n",
       "      <th>0.5</th>\n",
       "      <td>0.338082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.08</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>3.9</th>\n",
       "      <th>0.95</th>\n",
       "      <th>0.5</th>\n",
       "      <td>0.340065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.12</th>\n",
       "      <th>8</th>\n",
       "      <th>13</th>\n",
       "      <th>3.9</th>\n",
       "      <th>0.80</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.340487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.18</th>\n",
       "      <th>12</th>\n",
       "      <th>10</th>\n",
       "      <th>3.7</th>\n",
       "      <th>0.60</th>\n",
       "      <th>0.5</th>\n",
       "      <td>0.341646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <th>8</th>\n",
       "      <th>13</th>\n",
       "      <th>4.1</th>\n",
       "      <th>0.90</th>\n",
       "      <th>0.6</th>\n",
       "      <td>0.349470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.20</th>\n",
       "      <th>12</th>\n",
       "      <th>8</th>\n",
       "      <th>4.0</th>\n",
       "      <th>0.45</th>\n",
       "      <th>0.3</th>\n",
       "      <td>0.355765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>3.5</th>\n",
       "      <th>0.80</th>\n",
       "      <th>0.7</th>\n",
       "      <td>0.361761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.12</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>4.5</th>\n",
       "      <th>1.00</th>\n",
       "      <th>0.9</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.18</th>\n",
       "      <th>12</th>\n",
       "      <th>9</th>\n",
       "      <th>3.5</th>\n",
       "      <th>0.50</th>\n",
       "      <th>0.8</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.20</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th>9</th>\n",
       "      <th>4.1</th>\n",
       "      <th>0.85</th>\n",
       "      <th>0.4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <th>3.5</th>\n",
       "      <th>0.30</th>\n",
       "      <th>1.0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                         value\n",
       "params_colsample_bytree params_max_depth params_min_child_weight params_reg_alpha params_reg_lambda params_subsample          \n",
       "0.10                    8                13                      3.8              0.95              0.3               0.291473\n",
       "0.12                    10               12                      4.3              0.65              0.2               0.292010\n",
       "                                         13                      4.2              0.80              0.3               0.294662\n",
       "0.10                    8                13                      4.0              0.70              0.4               0.297268\n",
       "0.20                    12               14                      4.1              0.65              0.7               0.301110\n",
       "0.12                    10               13                      4.5              0.95              0.3               0.303032\n",
       "0.20                    10               8                       4.4              0.85              0.2               0.304179\n",
       "0.12                    10               13                      4.3              0.70              0.2               0.304889\n",
       "0.10                    10               11                      4.0              0.80              0.3               0.306882\n",
       "0.18                    12               12                      3.5              0.50              0.5               0.308752\n",
       "0.12                    10               13                      4.2              0.65              0.2               0.309299\n",
       "                        8                14                      4.3              0.55              0.3               0.310097\n",
       "0.10                    10               13                      4.1              0.75              0.2               0.312571\n",
       "0.12                    10               13                      4.4              0.65              0.3               0.312637\n",
       "0.10                    8                13                      3.8              0.65              0.4               0.312859\n",
       "0.12                    10               12                      4.3              0.70              0.2               0.314060\n",
       "0.10                    8                12                      3.6              0.90              0.3               0.314422\n",
       "0.12                    10               13                      4.3              0.55              0.3               0.315374\n",
       "                                         11                      3.7              0.45              0.4               0.315591\n",
       "                        8                12                      4.2              0.90              0.4               0.317170\n",
       "                        10               13                      4.4              0.75              0.2               0.318013\n",
       "0.18                    12               12                      3.9              0.60              0.7               0.319651\n",
       "0.12                    10               14                      4.4              0.95              0.3               0.320248\n",
       "0.08                    8                10                      4.3              0.70              0.2               0.323234\n",
       "0.18                    12               10                      3.6              0.75              0.2               0.324504\n",
       "0.12                    8                12                      3.8              0.70              0.4               0.324948\n",
       "0.10                    8                13                      4.0              0.70              0.3               0.325509\n",
       "                                         8                       4.2              0.60              0.3               0.326087\n",
       "                                                                 3.7              0.40              0.4               0.327188\n",
       "0.08                    10               14                      3.7              0.35              0.5               0.329007\n",
       "0.10                    10               10                      4.2              0.85              0.4               0.329069\n",
       "0.08                    8                13                      4.1              0.75              0.2               0.331206\n",
       "                                         14                      4.3              0.85              0.2               0.331383\n",
       "0.10                    8                13                      4.0              0.55              0.5               0.331402\n",
       "0.18                    12               11                      3.9              1.00              0.3               0.333932\n",
       "0.12                    10               13                      4.2              0.80              0.2               0.334107\n",
       "0.08                    12               13                      3.6              0.90              0.4               0.335340\n",
       "0.10                    8                13                      3.8              0.50              0.6               0.337475\n",
       "                                         8                       4.1              0.60              0.5               0.338082\n",
       "0.08                    10               12                      3.9              0.95              0.5               0.340065\n",
       "0.12                    8                13                      3.9              0.80              0.4               0.340487\n",
       "0.18                    12               10                      3.7              0.60              0.5               0.341646\n",
       "0.10                    8                13                      4.1              0.90              0.6               0.349470\n",
       "0.20                    12               8                       4.0              0.45              0.3               0.355765\n",
       "0.10                    8                9                       3.5              0.80              0.7               0.361761\n",
       "0.12                    10               11                      4.5              1.00              0.9                    NaN\n",
       "0.18                    12               9                       3.5              0.50              0.8                    NaN\n",
       "0.20                    10               9                       4.1              0.85              0.4                    NaN\n",
       "                                         12                      3.5              0.30              1.0                    NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    xgb_params = {\n",
    "        'learning_rate': 0.1,\n",
    "        'min_child_weight': trial.suggest_categorical('min_child_weight', [i for i in range(8, 15)]),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.3, 1, step=0.05),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 3.5, 4.5, step=0.1),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [8, 10, 12]),\n",
    "        'max_delta_step': 4,\n",
    "        'subsample': trial.suggest_float('subsample', 0.2, 1, step=0.1),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.08, 0.1, 0.12, 0.18, 0.2]),\n",
    "        'disable_default_eval_metric': True, \n",
    "        'seed': 5,\n",
    "    }\n",
    "\n",
    "    kf = StratifiedKFold(10, shuffle=True, random_state=30)\n",
    "    cols = X.columns.tolist()\n",
    "\n",
    "    xgb_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train_val, X_test = X.loc[train_index], X.loc[test_index]\n",
    "        y_train_val, y_test = y.loc[train_index], y.loc[test_index]\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.05, \n",
    "                                                          stratify=y_train_val, random_state=32)\n",
    "\n",
    "        sampler = RandomOverSampler()\n",
    "        X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "        n_components = 3\n",
    "        isomap = Isomap(n_components=n_components)\n",
    "        isomap.fit(X_train)\n",
    "\n",
    "        x_isomap_train = isomap.transform(X_train)\n",
    "        x_isomap_test = isomap.transform(X_test)\n",
    "        x_isomap_val = isomap.transform(X_val)\n",
    "\n",
    "        x_isomap_train = pd.DataFrame(x_isomap_train, columns=['isomap_' + str(i) for i in range(n_components)], index=X_train.index)\n",
    "        x_isomap_test = pd.DataFrame(x_isomap_test, columns=['isomap_' + str(i) for i in range(n_components)], index=X_test.index)\n",
    "        x_isomap_val = pd.DataFrame(x_isomap_val, columns=['isomap_' + str(i) for i in range(n_components)], index=X_val.index)\n",
    "\n",
    "        X_train = pd.concat([X_train, x_isomap_train], axis=1)\n",
    "        X_test = pd.concat([X_test, x_isomap_test], axis=1)\n",
    "        X_val = pd.concat([X_val, x_isomap_val], axis=1)\n",
    "        cols = X_train.columns.tolist()\n",
    "\n",
    "        dtrain_xgb = xgb.DMatrix(X_train, y_train, feature_names=cols, enable_categorical=True)\n",
    "        dtest_xgb = xgb.DMatrix(X_test, y_test, feature_names=cols, enable_categorical=True)\n",
    "        dval_xgb = xgb.DMatrix(X_val, y_val, feature_names=cols, enable_categorical=True)\n",
    "\n",
    "        xgb_model = xgb.train(params=xgb_params,\n",
    "                            dtrain=dtrain_xgb,\n",
    "                            verbose_eval=False,\n",
    "                            obj=balancedlogloss_xgb,\n",
    "                            evals=[(dtrain_xgb, 'train'), (dval_xgb, 'validation')],\n",
    "                            feval=balancedlogloss_eval_xgb,\n",
    "                            num_boost_round=300,\n",
    "                            early_stopping_rounds=10,\n",
    "                            )\n",
    "\n",
    "        xgb_test_preds = expit(xgb_model.predict(dtest_xgb, output_margin=True))\n",
    "\n",
    "        xgb_score = score(xgb_test_preds, y_test)\n",
    "        xgb_scores = xgb_scores + [xgb_score]\n",
    "\n",
    "    if np.isnan(np.mean(xgb_scores)):\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "    \n",
    "    return np.mean(xgb_scores)\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=5)\n",
    "study = optuna.create_study(direction='minimize', pruner=pruner)\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "trials_dataframe = study.trials_dataframe()\n",
    "get_trials_df(trials_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3480299219515556\n",
      "0.6758073702576946\n",
      "ensemble: 0.29074432262241634\n",
      "0.5432995333904612\n",
      "0.6806512668785927\n",
      "ensemble: 0.6201091008919584\n",
      "0.3705253818828417\n",
      "0.6764264054637226\n",
      "ensemble: 0.356120582796209\n",
      "0.4594165965285191\n",
      "0.6738122082665903\n",
      "ensemble: 0.47939363752571307\n",
      "0.21552427367561244\n",
      "0.6699694882385698\n",
      "ensemble: 0.16801681811198582\n",
      "0.2905431592883542\n",
      "0.6694373584885963\n",
      "ensemble: 0.3337217320382609\n",
      "0.28767757759593016\n",
      "0.6776906750851969\n",
      "ensemble: 0.2890359506125468\n",
      "0.23438752349016567\n",
      "0.6661445430226921\n",
      "ensemble: 0.23197171735571206\n",
      "0.24765286135516362\n",
      "0.6717067475850311\n",
      "ensemble: 0.3040891599995785\n",
      "0.11926825555710821\n",
      "0.6677202140269065\n",
      "ensemble: 0.11109402752703484\n",
      "\n",
      "\n",
      "xgb: 0.3116325084715712\n",
      "lgb: 0.6729366277313592\n",
      "ensemble:0.3184297049481416\n"
     ]
    }
   ],
   "source": [
    "# tuned but not completed\n",
    "xgb_param = study.best_params\n",
    "xgb_param['learning_rate'] = 0.1\n",
    "xgb_param['max_delta_step'] = 4\n",
    "xgb_param['seed'] = 5\n",
    "xgb_param['disable_default_eval_metric'] = True\n",
    "\n",
    "lgb_param = {'learning_rate': 0.2,\n",
    "             'lambda_l1': 40,\n",
    "             'lambda_l2': 10,\n",
    "             'subsample': 0.4,\n",
    "             'colsample_bytree': 0.5,\n",
    "             'verbosity': -1,\n",
    "             'boosting_type': 'goss',\n",
    "             }\n",
    "\n",
    "kf = StratifiedKFold(10, shuffle=True, random_state=30)\n",
    "cols = X.columns.tolist()\n",
    "\n",
    "df_xgb_train, df_xgb_test = pd.DataFrame(), pd.DataFrame()\n",
    "df_lgb_train, df_lgb_test = pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "xgb_scores = []\n",
    "lgb_scores = []\n",
    "scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "    X_train_val, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train_val, y_test = y.loc[train_index], y.loc[test_index]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=0.05, random_state=32)\n",
    "\n",
    "    sampler = RandomOverSampler()\n",
    "    X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "    n_components = 3\n",
    "    isomap = Isomap(n_components=n_components)\n",
    "    isomap.fit(X_train)\n",
    "\n",
    "    x_isomap_train = isomap.transform(X_train)\n",
    "    x_isomap_test = isomap.transform(X_test)\n",
    "    x_isomap_val = isomap.transform(X_val)\n",
    "\n",
    "    x_isomap_train = pd.DataFrame(x_isomap_train, columns=['isomap_' + str(i) for i in range(n_components)], index=X_train.index)\n",
    "    x_isomap_test = pd.DataFrame(x_isomap_test, columns=['isomap_' + str(i) for i in range(n_components)], index=X_test.index)\n",
    "    x_isomap_val = pd.DataFrame(x_isomap_val, columns=['isomap_' + str(i) for i in range(n_components)], index=X_val.index)\n",
    "\n",
    "    X_train = pd.concat([X_train, x_isomap_train], axis=1)\n",
    "    X_test = pd.concat([X_test, x_isomap_test], axis=1)\n",
    "    X_val = pd.concat([X_val, x_isomap_val], axis=1)\n",
    "    cols = X_train.columns.tolist()\n",
    "\n",
    "    evals_xgb = {}\n",
    "    dtrain_xgb = xgb.DMatrix(X_train, y_train, feature_names=cols, enable_categorical=True)\n",
    "    dtest_xgb = xgb.DMatrix(X_test, y_test, feature_names=cols, enable_categorical=True)\n",
    "    dval_xgb = xgb.DMatrix(X_val, y_val, feature_names=cols, enable_categorical=True)\n",
    "\n",
    "    xgb_model = xgb.train(params=xgb_param,\n",
    "                          dtrain=dtrain_xgb,\n",
    "                          obj=balancedlogloss_xgb,\n",
    "                          verbose_eval=False,\n",
    "                          evals=[(dtrain_xgb, 'train'), (dval_xgb, 'val')],\n",
    "                          feval=balancedlogloss_eval_xgb,\n",
    "                          evals_result=evals_xgb,\n",
    "                          early_stopping_rounds=20,\n",
    "                          num_boost_round=300,\n",
    "                          )\n",
    "    \n",
    "    df_xgb_train = pd.concat([df_xgb_train, pd.Series(evals_xgb['train']['balanced_logloss'])], axis=1)\n",
    "    df_xgb_test = pd.concat([df_xgb_test, pd.Series(evals_xgb['val']['balanced_logloss'])], axis=1)\n",
    "\n",
    "    xgb_train_preds = expit(xgb_model.predict(dtrain_xgb, output_margin=True))\n",
    "    xgb_test_preds = expit(xgb_model.predict(dtest_xgb, output_margin=True))\n",
    "\n",
    "    xgb_score = score(xgb_test_preds, y_test)\n",
    "    xgb_scores = xgb_scores + [xgb_score]\n",
    "    print(xgb_score)\n",
    "\n",
    "    evals_lgb = {}\n",
    "    dtrain_lgb = lgb.Dataset(X_train, y_train)\n",
    "    dtest_lgb = lgb.Dataset(X_test, y_test)\n",
    "    dval_lgb = lgb.Dataset(X_val, y_val)\n",
    "\n",
    "    lgb_model = lgb.train(params=lgb_param,\n",
    "                          train_set=dtrain_lgb,\n",
    "                          valid_sets=[dtrain_lgb, dval_lgb],\n",
    "                          fobj=balancedlogloss_lgb,\n",
    "                          feval=balancedlogloss_eval_lgb,\n",
    "                          evals_result=evals_lgb,\n",
    "                          valid_names=['train', 'val'],\n",
    "                          num_boost_round=500,\n",
    "                          early_stopping_rounds=2,\n",
    "                          verbose_eval=False)\n",
    "\n",
    "    df_lgb_train = pd.concat([df_lgb_train, pd.Series(evals_lgb['train']['balanced_logloss'])], axis=1)\n",
    "    df_lgb_test = pd.concat([df_lgb_test, pd.Series(evals_lgb['val']['balanced_logloss'])], axis=1)\n",
    "\n",
    "    lgb_train_preds = expit(lgb_model.predict(X_train, raw_score=True))\n",
    "    lgb_test_preds = expit(lgb_model.predict(X_test, raw_score=True))\n",
    "\n",
    "    lgb_score = score(lgb_test_preds, y_test)\n",
    "    lgb_scores = lgb_scores + [lgb_score]\n",
    "    print(lgb_score)\n",
    "\n",
    "    stacked_preds_train = np.column_stack(((expit(xgb_train_preds)), (expit(lgb_train_preds))))\n",
    "    stacked_preds_test = np.column_stack(((expit(xgb_test_preds)), (expit(lgb_test_preds))))\n",
    "\n",
    "    meta_model = LogisticRegression(C=10, random_state=20)\n",
    "    # meta_model = xgb.XGBClassifier()\n",
    "    meta_model.fit(stacked_preds_train, y_train)\n",
    "    ensemble_preds = meta_model.predict_proba(stacked_preds_test)[:, 1]\n",
    "\n",
    "    ensemble_score = score(ensemble_preds, np.array(y_test))\n",
    "    scores = scores + [ensemble_score]\n",
    "    print('ensemble: ' + str(ensemble_score))\n",
    "\n",
    "df_xgb = pd.DataFrame()\n",
    "df_xgb['train'] = df_xgb_train.mean(axis=1)\n",
    "df_xgb['val'] = df_xgb_test.mean(axis=1)\n",
    "\n",
    "df_lgb = pd.DataFrame()\n",
    "df_lgb['train'] = df_lgb_train.mean(axis=1)\n",
    "df_lgb['val'] = df_lgb_test.mean(axis=1)\n",
    "\n",
    "print('\\n')\n",
    "print('xgb: ' + str(np.mean(xgb_scores)))\n",
    "print('lgb: ' + str(np.mean(lgb_scores)))\n",
    "print('ensemble:' + str(np.mean(scores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
