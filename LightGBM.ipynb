{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import ray\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    balanced_accuracy_score,\n",
    ")\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, SMOTENC\n",
    "from sklearn.utils import compute_class_weight, class_weight\n",
    "from sklearn.manifold import Isomap\n",
    "from typing import Tuple\n",
    "from scipy.special import expit\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train['EJ'].replace(['A', 'B'], [1, 0], inplace=True)\n",
    "\n",
    "ej = np.array(train['EJ']).reshape(-1, 1)\n",
    "\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "y = np.array(train['Class'])\n",
    "\n",
    "greeks = pd.read_csv('greeks.csv')\n",
    "greeks['Epsilon'].replace(['Unknown'], np.nan, inplace=True)\n",
    "\n",
    "train_greeks = pd.merge(train, greeks, on='Id')\n",
    "greek_columns = greeks.columns.drop(['Id', 'Epsilon', 'Alpha']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_numerical_columns = train.drop(columns=[\"Id\", \"Class\", \"EJ\"]).columns.tolist()\n",
    "x_categorical_columns = [\"EJ\"]\n",
    "x_cols = x_numerical_columns + x_categorical_columns\n",
    "\n",
    "scaler.fit(train_greeks[x_numerical_columns])\n",
    "x_standardized = scaler.transform(train_greeks[x_numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "knn = KNNImputer()\n",
    "knn.fit(x_standardized)\n",
    "x_imputed_standardized = knn.transform(x_standardized)\n",
    "\n",
    "X = np.concatenate((x_imputed_standardized, ej), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df(arr):\n",
    "    cols = x_numerical_columns + x_categorical_columns\n",
    "    df = pd.DataFrame(arr, columns=cols)\n",
    "    df[x_categorical_columns] = df[x_categorical_columns].astype(\"category\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancedlogloss(\n",
    "    predt: np.ndarray, dtrain: lgb.Dataset\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    y = dtrain.get_label()\n",
    "    n0 = len(y[y == 0])\n",
    "    n1 = len(y[y == 1])\n",
    "\n",
    "    p = expit(predt)\n",
    "    p[p == 0] = 1e-15\n",
    "\n",
    "    grad = 1 / 2 * ((1 - y) / (1 - p) - y / p)\n",
    "    hess = 1 / 2 * ((1 - y) / ((1 - p) ** 2) + y / (p**2))\n",
    "    return grad, hess\n",
    "\n",
    "\n",
    "def balancedlogloss_eval_lgb(\n",
    "    predt: np.ndarray, dtrain: lgb.Dataset\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    y = dtrain.get_label()\n",
    "    n0 = len(y[y == 0])\n",
    "    n1 = len(y[y == 1])\n",
    "    p = expit(predt)\n",
    "\n",
    "    p[p == 0] = 1e-15\n",
    "\n",
    "    return (\n",
    "        \"balanced_logloss\",\n",
    "        (-1 / n0 * (sum((1 - y) * np.log(1 - p))) - 1 / n1 * (sum(y * np.log(p)))) / 2,\n",
    "        True\n",
    "    )\n",
    "\n",
    "def balancedlogloss_eval_xgb(\n",
    "    predt: np.ndarray, dtrain: lgb.Dataset\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    y = dtrain.get_label()\n",
    "    n0 = len(y[y == 0])\n",
    "    n1 = len(y[y == 1])\n",
    "    p = expit(predt)\n",
    "\n",
    "    p[p == 0] = 1e-15\n",
    "\n",
    "    return (\n",
    "        \"balanced_logloss\",\n",
    "        (-1 / n0 * (sum((1 - y) * np.log(1 - p))) - 1 / n1 * (sum(y * np.log(p)))) / 2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5414611634858639\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.682868</td>\n",
       "      <td>0.687094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.359749</td>\n",
       "      <td>0.541789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.252408</td>\n",
       "      <td>0.594782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.211499</td>\n",
       "      <td>0.712240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.192777</td>\n",
       "      <td>0.865528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.181095</td>\n",
       "      <td>1.025092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.174093</td>\n",
       "      <td>1.184912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0.170040</td>\n",
       "      <td>1.368567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        train      test\n",
       "0    0.682868  0.687094\n",
       "50   0.359749  0.541789\n",
       "100  0.252408  0.594782\n",
       "150  0.211499  0.712240\n",
       "200  0.192777  0.865528\n",
       "250  0.181095  1.025092\n",
       "300  0.174093  1.184912\n",
       "350  0.170040  1.368567"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cv(X_kf, y_kf, lgb_param, num_boost_round=100):\n",
    "    \n",
    "    train_evals = pd.DataFrame()\n",
    "    test_evals = pd.DataFrame()\n",
    "\n",
    "    kf = StratifiedKFold(10, random_state=3, shuffle=True)\n",
    "    k = 0\n",
    "\n",
    "    for train_index, test_index in kf.split(X_kf, y_kf):\n",
    "        X_train = pd.DataFrame(X_kf[train_index], columns=x_cols)\n",
    "        X_test = pd.DataFrame(X_kf[test_index], columns=x_cols)\n",
    "        y_train = y_kf[train_index]\n",
    "        y_test = y_kf[test_index]\n",
    "\n",
    "        # sampler = RandomOverSampler()\n",
    "        sampler = SMOTE()\n",
    "        X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "        n_components = 40\n",
    "        dr_cols = ['Isomap'+str(i) for i in range(n_components)]\n",
    "        dr = Isomap(n_components=n_components)\n",
    "        dr.fit(X_train)\n",
    "        X_train_dr = pd.DataFrame(dr.transform(X_train), columns=dr_cols)\n",
    "        X_test_dr = pd.DataFrame(dr.transform(X_test), columns=dr_cols)\n",
    "\n",
    "        train_set = lgb.Dataset(X_train_dr, y_train)\n",
    "        test_set = lgb.Dataset(X_test_dr, y_test)\n",
    "\n",
    "        # X_train = pd.concat([X_train, X_train_dr], axis=1)\n",
    "        # X_test = pd.concat([X_test, X_test_dr], axis=1)\n",
    "        # cols = X_train.columns.tolist()\n",
    "\n",
    "        # train_set = lgb.Dataset(X_train, y_train, feature_name=cols)\n",
    "        # test_set = lgb.Dataset(X_test, y_test, feature_name=cols)\n",
    "\n",
    "        evals = {}\n",
    "        lgb_model = lgb.train(\n",
    "                        params=lgb_param,\n",
    "                        train_set=train_set,\n",
    "                        # categorical_feature=['EJ'],\n",
    "                        valid_sets=[train_set, test_set],\n",
    "                        verbose_eval=False,\n",
    "                        fobj=balancedlogloss,\n",
    "                        feval=balancedlogloss_eval_lgb,\n",
    "                        num_boost_round=num_boost_round,\n",
    "                        evals_result=evals\n",
    "                        )\n",
    "\n",
    "        train_evals[str(k)] = evals[\"training\"][\"balanced_logloss\"]\n",
    "        test_evals[str(k)] = evals[\"valid_1\"][\"balanced_logloss\"]\n",
    "        k = k + 1\n",
    "\n",
    "    eval_df = pd.concat([train_evals.mean(axis=1, skipna=False), test_evals.mean(axis=1, skipna=False)], axis=1)\n",
    "    eval_df.columns = ['train', 'test']\n",
    "    return eval_df\n",
    "\n",
    "lgb_param = {'learning_rate': 0.1,\n",
    "             'subsample': 0.7,\n",
    "             'max_depth': 4,\n",
    "             'lambda_l1': 30,\n",
    "             'lambda_l2': 30,\n",
    "             'verbosity': -1\n",
    "            }\n",
    "\n",
    "\n",
    "cv_results = cv(X, y, lgb_param, num_boost_round=400)\n",
    "\n",
    "print(cv_results['test'].min())\n",
    "cv_results.iloc[range(0, len(cv_results), 50)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "param_space = {\n",
    "    'num_leaves': [10, 50, 100, 300],\n",
    "    'max_depth': [5, 30, 50, 70],\n",
    "    'lambda_l1': [0.02, 0.5, 10],\n",
    "    'lambda_l2': [30], \n",
    "    'verbosity': [-1]\n",
    "}\n",
    "\n",
    "grid = ParameterGrid(param_space)\n",
    "\n",
    "for params_grid in grid:\n",
    "    print(params_grid)\n",
    "\n",
    "    cv_results = cv(X, y, params_grid, num_boost_round=400)\n",
    "    print(cv_results['test'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" test = pd.read_csv(\"test.csv\")\n",
    "test[\"EJ\"].replace([\"A\", \"B\"], [1, 0], inplace=True)\n",
    "test_ej = np.array(test[\"EJ\"]).reshape(-1, 1)\n",
    "\n",
    "x_test_scaled = scaler.transform(test[x_numerical_columns])\n",
    "\n",
    "X_test = np.append(x_test_scaled, test_ej, axis=1) \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
