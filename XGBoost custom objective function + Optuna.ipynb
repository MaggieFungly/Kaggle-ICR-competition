{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do list:\n",
    "\n",
    "Try greek information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from typing import Tuple\n",
    "from scipy.special import expit\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train['EJ'].replace(['A', 'B'], [1, 0], inplace=True)\n",
    "\n",
    "ej = np.array(pd.get_dummies(train['EJ']))\n",
    "\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "y = np.array(train['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "x_numerical_columns = train.drop(columns=['Id', 'Class', 'EJ']).columns\n",
    "\n",
    "scaler.fit(train[x_numerical_columns])\n",
    "x_standardized = scaler.transform(train[x_numerical_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "knn = KNNImputer()\n",
    "knn.fit(x_standardized)\n",
    "x_imputed_standardized = knn.transform(x_standardized)\n",
    "\n",
    "X = np.append(x_imputed_standardized, ej, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancedlogloss(predt: np.ndarray, dtrain: xgb.DMatrix) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    y = dtrain.get_label()\n",
    "    n0 = len(y[y==0])\n",
    "    n1 = len(y[y==1])\n",
    "\n",
    "    p = expit(predt)\n",
    "\n",
    "    p[p==0] = 1e-15\n",
    "\n",
    "    grad = 1/2*((1-y)/(1-p)-y/p)\n",
    "    hess = 1/2*((1-y)/((1-p)**2)+y/(p**2))\n",
    "    return grad, hess\n",
    "\n",
    "def scoring(y, p):\n",
    "\n",
    "    p = expit(p)\n",
    "\n",
    "    p[p==0] = 1e-15\n",
    "\n",
    "    n0 = len(y[y==0])\n",
    "    n1 = len(y[y==1])\n",
    "    \n",
    "    return (-1/n0*(sum((1-y)*np.log(1-p)))-1/n1*(sum(y*np.log(p))))/2\n",
    "\n",
    "def balancedlogloss_eval(predt: np.ndarray, dtrain: xgb.DMatrix) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    y = dtrain.get_label()\n",
    "    n0 = len(y[y==0])\n",
    "    n1 = len(y[y==1])\n",
    "    p = expit(predt)\n",
    "\n",
    "    p[p==0] = 1e-15\n",
    "\n",
    "    return 'balanced_logloss', (-1/n0*(sum((1-y)*np.log(1-p)))-1/n1*(sum(y*np.log(p))))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    optimized_param = {'learning_rate': trial.suggest_float('learning_rate', 1e-3, 2, step=0.02),\n",
    "                       'gamma': trial.suggest_float('gamma', 1e-3, 2.0, step=0.005),\n",
    "                       'reg_lambda': trial.suggest_float('reg_lambda', 1, 100, step=10),\n",
    "                       # 'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1e-3, 10),\n",
    "                       'max_depth': trial.suggest_int('max_depth', 2, 10),\n",
    "                       'min_child_weight': trial.suggest_float('min_child_weight', 0.1, 0.95, step=0.1),\n",
    "                       'max_delta_step': trial.suggest_int('max_delta_step', 1, 5),\n",
    "                        }\n",
    "    \n",
    "    # Perform 10-fold cross-validation\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "    mean_balanced_logloss_score = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        sampler = RandomOverSampler()\n",
    "        X_re, y_re = sampler.fit_resample(X_train, y_train)\n",
    "        \n",
    "        # Train a XGBoost model\n",
    "        train_set = xgb.DMatrix(X_re, y_re)\n",
    "        test_set = xgb.DMatrix(X_test, y_test)\n",
    "        \n",
    "        clf = xgb.train(params=optimized_param,\n",
    "                        dtrain=train_set,\n",
    "                        obj=balancedlogloss,\n",
    "                        feval=balancedlogloss_eval,\n",
    "                        )\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        preds = clf.predict(xgb.DMatrix(X_test), output_margin=True)\n",
    "        \n",
    "        # Calculate the balanced logloss score\n",
    "        ll = scoring(y=y_test, p=preds)\n",
    "        mean_balanced_logloss_score.append(ll)\n",
    "    \n",
    "    return np.mean(mean_balanced_logloss_score)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "optimization_results = pd.DataFrame([study.trials[i].params for i in range(len(study.trials))])\n",
    "optimization_results['score'] = [study.trials[i].value for i in range(len(study.trials))]\n",
    "optimization_results = optimization_results.sort_values(by='score')\n",
    "\n",
    "optimization_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tdtrain-balanced_logloss:0.62521\tdval-balanced_logloss:0.60090\n",
      "[5]\tdtrain-balanced_logloss:0.28174\tdval-balanced_logloss:0.23436\n",
      "[9]\tdtrain-balanced_logloss:0.17818\tdval-balanced_logloss:0.14367\n",
      "balanced log loss: 0.15190405318779604\n",
      "\n",
      "\n",
      "[0]\tdtrain-balanced_logloss:0.61934\tdval-balanced_logloss:0.59994\n",
      "[5]\tdtrain-balanced_logloss:0.27003\tdval-balanced_logloss:0.25566\n",
      "[9]\tdtrain-balanced_logloss:0.16164\tdval-balanced_logloss:0.19656\n",
      "balanced log loss: 0.14238052896135264\n",
      "\n",
      "\n",
      "[0]\tdtrain-balanced_logloss:0.61890\tdval-balanced_logloss:0.63215\n",
      "[5]\tdtrain-balanced_logloss:0.25641\tdval-balanced_logloss:0.55371\n",
      "[9]\tdtrain-balanced_logloss:0.16063\tdval-balanced_logloss:0.58318\n",
      "balanced log loss: 0.1480838910876108\n",
      "\n",
      "\n",
      "[0]\tdtrain-balanced_logloss:0.61239\tdval-balanced_logloss:0.63664\n",
      "[5]\tdtrain-balanced_logloss:0.25605\tdval-balanced_logloss:0.39846\n",
      "[9]\tdtrain-balanced_logloss:0.16264\tdval-balanced_logloss:0.40761\n",
      "balanced log loss: 0.1367014557167533\n",
      "\n",
      "\n",
      "[0]\tdtrain-balanced_logloss:0.61744\tdval-balanced_logloss:0.67173\n",
      "[5]\tdtrain-balanced_logloss:0.26219\tdval-balanced_logloss:0.30858\n",
      "[9]\tdtrain-balanced_logloss:0.16242\tdval-balanced_logloss:0.19641\n",
      "balanced log loss: 0.17108415345483946\n",
      "\n",
      "\n",
      "[0]\tdtrain-balanced_logloss:0.61720\tdval-balanced_logloss:0.63849\n",
      "[5]\tdtrain-balanced_logloss:0.25607\tdval-balanced_logloss:0.49539\n",
      "[9]\tdtrain-balanced_logloss:0.19262\tdval-balanced_logloss:0.53297\n",
      "balanced log loss: 0.2049593347640309\n",
      "\n",
      "\n",
      "[0]\tdtrain-balanced_logloss:0.61571\tdval-balanced_logloss:0.67703\n",
      "[5]\tdtrain-balanced_logloss:0.27097\tdval-balanced_logloss:0.44069\n",
      "[9]\tdtrain-balanced_logloss:0.17869\tdval-balanced_logloss:0.39892\n",
      "balanced log loss: 0.1617629820747035\n",
      "\n",
      "\n",
      "[0]\tdtrain-balanced_logloss:0.60889\tdval-balanced_logloss:0.67032\n",
      "[5]\tdtrain-balanced_logloss:0.25667\tdval-balanced_logloss:0.46083\n",
      "[9]\tdtrain-balanced_logloss:0.17120\tdval-balanced_logloss:0.36907\n",
      "balanced log loss: 0.17878858551072577\n",
      "\n",
      "\n",
      "[0]\tdtrain-balanced_logloss:0.61644\tdval-balanced_logloss:0.66944\n",
      "[5]\tdtrain-balanced_logloss:0.25650\tdval-balanced_logloss:0.58644\n",
      "[9]\tdtrain-balanced_logloss:0.17155\tdval-balanced_logloss:0.58776\n",
      "balanced log loss: 0.14769816972936192\n",
      "\n",
      "\n",
      "[0]\tdtrain-balanced_logloss:0.61295\tdval-balanced_logloss:0.62077\n",
      "[5]\tdtrain-balanced_logloss:0.26727\tdval-balanced_logloss:0.31828\n",
      "[9]\tdtrain-balanced_logloss:0.17815\tdval-balanced_logloss:0.27125\n",
      "balanced log loss: 0.17247841093644853\n",
      "\n",
      "\n",
      "0.1615841565423623\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "best_params['disable_default_eval_metric'] = True\n",
    "best_params['verbosity']=0\n",
    "best_params['seed']=6\n",
    "\n",
    "scores = []\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, \n",
    "                                                            test_size=0.05, \n",
    "                                                            # random_state=20, \n",
    "                                                            shuffle=False)\n",
    "dtest = xgb.DMatrix(X_test, y_test)\n",
    "\n",
    "\n",
    "for i in range(0, 10):\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.05, shuffle=True)\n",
    "    sampler_model = RandomOverSampler()\n",
    "    X_re, y_re = sampler_model.fit_resample(X_train, y_train)\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_re, y_re)\n",
    "    dval = xgb.DMatrix(X_val, y_val)\n",
    "\n",
    "    model = xgb.train(params=best_params,\n",
    "                      dtrain=dtrain,\n",
    "                      obj=balancedlogloss,\n",
    "                      evals=[(dtrain, 'dtrain'), (dval, 'dval')],\n",
    "                      feval=balancedlogloss_eval, \n",
    "                      verbose_eval=5,\n",
    "                      early_stopping_rounds=5\n",
    "                      )\n",
    "\n",
    "    scores = scores + [scoring(y=y_test, p=model.predict(dtest, output_margin=True))]\n",
    "\n",
    "    print('balanced log loss: ' + str(scoring(y=y_test, p=model.predict(dtest, output_margin=True))))\n",
    "    print('\\n')\n",
    "\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tdtrain-balanced_logloss:0.61328\tdval-balanced_logloss:0.62704\n",
      "[5]\tdtrain-balanced_logloss:0.25886\tdval-balanced_logloss:0.32987\n",
      "[9]\tdtrain-balanced_logloss:0.16999\tdval-balanced_logloss:0.23159\n",
      "\n",
      "\n",
      "[0]\tdtrain-balanced_logloss:0.61653\tdval-balanced_logloss:0.61232\n",
      "[5]\tdtrain-balanced_logloss:0.27242\tdval-balanced_logloss:0.29932\n",
      "[9]\tdtrain-balanced_logloss:0.18532\tdval-balanced_logloss:0.16908\n",
      "\n",
      "\n",
      "[0]\tdtrain-balanced_logloss:0.61862\tdval-balanced_logloss:0.64976\n",
      "[5]\tdtrain-balanced_logloss:0.26078\tdval-balanced_logloss:0.38419\n",
      "[9]\tdtrain-balanced_logloss:0.18083\tdval-balanced_logloss:0.26106\n",
      "\n",
      "\n",
      "[0]\tdtrain-balanced_logloss:0.61955\tdval-balanced_logloss:0.60142\n",
      "[5]\tdtrain-balanced_logloss:0.26328\tdval-balanced_logloss:0.28250\n",
      "[9]\tdtrain-balanced_logloss:0.17536\tdval-balanced_logloss:0.23096\n",
      "\n",
      "\n",
      "[0]\tdtrain-balanced_logloss:0.61040\tdval-balanced_logloss:0.68194\n",
      "[5]\tdtrain-balanced_logloss:0.25809\tdval-balanced_logloss:0.44859\n",
      "[9]\tdtrain-balanced_logloss:0.16985\tdval-balanced_logloss:0.35369\n",
      "\n",
      "\n",
      "[0]\tdtrain-balanced_logloss:0.61538\tdval-balanced_logloss:0.67077\n",
      "[5]\tdtrain-balanced_logloss:0.25852\tdval-balanced_logloss:0.44104\n",
      "[9]\tdtrain-balanced_logloss:0.18005\tdval-balanced_logloss:0.41546\n",
      "\n",
      "\n",
      "[0]\tdtrain-balanced_logloss:0.61713\tdval-balanced_logloss:0.62504\n",
      "[5]\tdtrain-balanced_logloss:0.25487\tdval-balanced_logloss:0.39180\n",
      "[9]\tdtrain-balanced_logloss:0.17185\tdval-balanced_logloss:0.39657\n",
      "\n",
      "\n",
      "[0]\tdtrain-balanced_logloss:0.60903\tdval-balanced_logloss:0.63581\n",
      "[5]\tdtrain-balanced_logloss:0.26181\tdval-balanced_logloss:0.26703\n",
      "[9]\tdtrain-balanced_logloss:0.18011\tdval-balanced_logloss:0.16061\n",
      "\n",
      "\n",
      "[0]\tdtrain-balanced_logloss:0.61890\tdval-balanced_logloss:0.64718\n",
      "[5]\tdtrain-balanced_logloss:0.25991\tdval-balanced_logloss:0.39746\n",
      "[9]\tdtrain-balanced_logloss:0.16350\tdval-balanced_logloss:0.30262\n",
      "\n",
      "\n",
      "[0]\tdtrain-balanced_logloss:0.61489\tdval-balanced_logloss:0.63055\n",
      "[5]\tdtrain-balanced_logloss:0.26168\tdval-balanced_logloss:0.31011\n",
      "[9]\tdtrain-balanced_logloss:0.17710\tdval-balanced_logloss:0.22925\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test['EJ'].replace(['A', 'B'], [1, 0], inplace=True)\n",
    "\n",
    "test_ej = np.array(pd.get_dummies(test['EJ']))\n",
    "\n",
    "x_test_scaled = scaler.transform(test[x_numerical_columns])\n",
    "\n",
    "X_test = np.append(x_test_scaled, test_ej, axis=1)\n",
    "d_test = xgb.DMatrix(X_test)\n",
    "\n",
    "preds = pd.DataFrame(index=range(test.shape[0]))\n",
    "\n",
    "for i in range(0, 10):\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.05, shuffle=True)\n",
    "    sampler_model = RandomOverSampler()\n",
    "    X_re, y_re = sampler_model.fit_resample(X_train, y_train)\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_re, y_re)\n",
    "    dval = xgb.DMatrix(X_val, y_val)\n",
    "\n",
    "    model = xgb.train(params=best_params,\n",
    "                      dtrain=dtrain,\n",
    "                      obj=balancedlogloss,\n",
    "                      evals=[(dtrain, 'dtrain'), (dval, 'dval')],\n",
    "                      feval=balancedlogloss_eval,\n",
    "                      verbose_eval=5,\n",
    "                      early_stopping_rounds=5\n",
    "                      )\n",
    "\n",
    "    p = expit(model.predict(d_test))\n",
    "    p = pd.Series(p)\n",
    "\n",
    "    preds = pd.concat([preds, p], axis=1)\n",
    "    print('\\n')\n",
    "\n",
    "pred_1 = np.mean(preds, axis=1)\n",
    "pred_0 = 1 - pred_1\n",
    "\n",
    "# pred_0\n",
    "\n",
    "submission = pd.DataFrame(index=test.index, columns=sample_submission.columns)\n",
    "submission['Id'] = test['Id']\n",
    "submission['class_0'] = pred_0\n",
    "submission['class_1'] = pred_1\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00eed32682bb</td>\n",
       "      <td>0.881854</td>\n",
       "      <td>0.118146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010ebe33f668</td>\n",
       "      <td>0.881854</td>\n",
       "      <td>0.118146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02fa521e1838</td>\n",
       "      <td>0.881854</td>\n",
       "      <td>0.118146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>040e15f562a2</td>\n",
       "      <td>0.881854</td>\n",
       "      <td>0.118146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>046e85c7cc7f</td>\n",
       "      <td>0.881854</td>\n",
       "      <td>0.118146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id   class_0   class_1\n",
       "0  00eed32682bb  0.881854  0.118146\n",
       "1  010ebe33f668  0.881854  0.118146\n",
       "2  02fa521e1838  0.881854  0.118146\n",
       "3  040e15f562a2  0.881854  0.118146\n",
       "4  046e85c7cc7f  0.881854  0.118146"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
