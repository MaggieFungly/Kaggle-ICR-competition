{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport sklearn\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\n\n# from IPython.display import set_matplotlib_formats\n# set_matplotlib_formats('retina')\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport lightgbm as lgb\nimport optuna\nfrom sklearn.model_selection import KFold, StratifiedKFold, train_test_split\nfrom imblearn.over_sampling import RandomOverSampler\n\nfrom typing import Tuple\nfrom scipy.special import expit\nimport xgboost as xgb","metadata":{"execution":{"iopub.status.busy":"2023-06-06T05:27:34.401962Z","iopub.execute_input":"2023-06-06T05:27:34.402365Z","iopub.status.idle":"2023-06-06T05:27:34.410334Z","shell.execute_reply.started":"2023-06-06T05:27:34.402334Z","shell.execute_reply":"2023-06-06T05:27:34.408963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/train.csv')\n\ntrain['EJ'].replace(['A', 'B'], [1, 0], inplace=True)\n\nej = np.array(pd.get_dummies(train['EJ']))\n\nsample_submission = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv')\n\ny = np.array(train['Class'])","metadata":{"execution":{"iopub.status.busy":"2023-06-06T05:27:34.412022Z","iopub.execute_input":"2023-06-06T05:27:34.413098Z","iopub.status.idle":"2023-06-06T05:27:34.447005Z","shell.execute_reply.started":"2023-06-06T05:27:34.413052Z","shell.execute_reply":"2023-06-06T05:27:34.445774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nscaler = MinMaxScaler()\n\nx_numerical_columns = train.drop(columns=['Id', 'Class', 'EJ']).columns\n\nscaler.fit(train[x_numerical_columns])\nx_standardized = scaler.transform(train[x_numerical_columns])","metadata":{"execution":{"iopub.status.busy":"2023-06-06T05:27:34.448325Z","iopub.execute_input":"2023-06-06T05:27:34.448654Z","iopub.status.idle":"2023-06-06T05:27:34.464173Z","shell.execute_reply.started":"2023-06-06T05:27:34.448626Z","shell.execute_reply":"2023-06-06T05:27:34.462969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.impute import KNNImputer\n\nknn = KNNImputer()\nknn.fit(x_standardized)\nx_imputed_standardized = knn.transform(x_standardized)\n\nX = np.append(x_imputed_standardized, ej, axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T05:27:34.465670Z","iopub.execute_input":"2023-06-06T05:27:34.466139Z","iopub.status.idle":"2023-06-06T05:27:34.498551Z","shell.execute_reply.started":"2023-06-06T05:27:34.466101Z","shell.execute_reply":"2023-06-06T05:27:34.496919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def balancedlogloss(predt: np.ndarray, dtrain: xgb.DMatrix) -> Tuple[np.ndarray, np.ndarray]:\n    y = dtrain.get_label()\n    n0 = len(y[y==0])\n    n1 = len(y[y==1])\n\n    p = expit(predt)\n\n    p[p==0] = 1e-15\n\n    grad = 1/2*((1-y)/(1-p)-y/p)\n    hess = 1/2*((1-y)/((1-p)**2)+y/(p**2))\n    return grad, hess\n\ndef scoring(y, p):\n\n    p = expit(p)\n\n    p[p==0] = 1e-15\n\n    n0 = len(y[y==0])\n    n1 = len(y[y==1])\n    \n    return (-1/n0*(sum((1-y)*np.log(1-p)))-1/n1*(sum(y*np.log(p))))/2\n\ndef balancedlogloss_eval(predt: np.ndarray, dtrain: xgb.DMatrix) -> Tuple[np.ndarray, np.ndarray]:\n    y = dtrain.get_label()\n    n0 = len(y[y==0])\n    n1 = len(y[y==1])\n    p = expit(predt)\n\n    p[p==0] = 1e-15\n\n    return 'balanced_logloss', (-1/n0*(sum((1-y)*np.log(1-p)))-1/n1*(sum(y*np.log(p))))/2","metadata":{"execution":{"iopub.status.busy":"2023-06-06T05:27:34.505109Z","iopub.execute_input":"2023-06-06T05:27:34.506288Z","iopub.status.idle":"2023-06-06T05:27:34.528982Z","shell.execute_reply.started":"2023-06-06T05:27:34.506227Z","shell.execute_reply":"2023-06-06T05:27:34.526816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n    optimized_param = {'learning_rate': trial.suggest_float('learning_rate', 1e-3, 2, step=0.004),\n                       'gamma': trial.suggest_float('gamma', 1e-3, 2.0, step=0.005),\n                       'reg_lambda': trial.suggest_float('reg_lambda', 1, 100, step=10),\n                       # 'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1e-3, 10),\n                       'max_depth': trial.suggest_int('max_depth', 2, 10),\n                       'min_child_weight': trial.suggest_float('min_child_weight', 0.1, 0.95, step=0.1),\n                       'max_delta_step': trial.suggest_int('max_delta_step', 1, 5),\n                        }\n    \n    # Perform 10-fold cross-validation\n    kf = KFold(n_splits=10, shuffle=True)\n    mean_balanced_logloss_score = []\n\n    for train_index, test_index in kf.split(X):\n\n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n\n        sampler = RandomOverSampler()\n        X_re, y_re = sampler.fit_resample(X_train, y_train)\n        \n        # Train a XGBoost model\n        train_set = xgb.DMatrix(X_re, y_re)\n        test_set = xgb.DMatrix(X_test, y_test)\n        \n        clf = xgb.train(params=optimized_param,\n                        dtrain=train_set,\n                        obj=balancedlogloss,\n                        )\n\n        # Make predictions on the test set\n        preds = clf.predict(xgb.DMatrix(X_test), output_margin=True)\n        \n        # Calculate the balanced logloss score\n        ll = scoring(y=y_test, p=preds)\n        mean_balanced_logloss_score.append(ll)\n    \n    return np.mean(mean_balanced_logloss_score)\n\n\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=100)\n\noptimization_results = pd.DataFrame([study.trials[i].params for i in range(len(study.trials))])\noptimization_results['score'] = [study.trials[i].value for i in range(len(study.trials))]\noptimization_results = optimization_results.sort_values(by='score')\n\noptimization_results","metadata":{"execution":{"iopub.status.busy":"2023-06-06T05:27:34.531254Z","iopub.execute_input":"2023-06-06T05:27:34.531944Z","iopub.status.idle":"2023-06-06T05:28:24.904528Z","shell.execute_reply.started":"2023-06-06T05:27:34.531880Z","shell.execute_reply":"2023-06-06T05:28:24.903306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_params = study.best_params\nbest_params['disable_default_eval_metric'] = True\nbest_params['verbosity']=0\nbest_params['seed']=6\n\nscores = []\n\nX_train_val, X_test, y_train_val, y_test = train_test_split(X, y, \n                                                            test_size=0.05, \n                                                            # random_state=20, \n                                                            shuffle=False)\ndtest = xgb.DMatrix(X_test, y_test)\n\n\nfor i in range(0, 10):\n\n    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.05, shuffle=True)\n    sampler_model = RandomOverSampler()\n    X_re, y_re = sampler_model.fit_resample(X_train, y_train)\n\n    dtrain = xgb.DMatrix(X_re, y_re)\n    dval = xgb.DMatrix(X_val, y_val)\n\n    model = xgb.train(params=best_params,\n                      dtrain=dtrain,\n                      obj=balancedlogloss,\n                      evals=[(dtrain, 'dtrain'), (dval, 'dval')],\n                      feval=balancedlogloss_eval, \n                      verbose_eval=5,\n                      early_stopping_rounds=5\n                      )\n\n    scores = scores + [scoring(y=y_test, p=model.predict(dtest, output_margin=True))]\n\n    print('balanced log loss: ' + str(scoring(y=y_test, p=model.predict(dtest, output_margin=True))))\n    print('\\n')\n\nprint(np.mean(scores))","metadata":{"execution":{"iopub.status.busy":"2023-06-06T05:29:09.309716Z","iopub.execute_input":"2023-06-06T05:29:09.310148Z","iopub.status.idle":"2023-06-06T05:29:09.941396Z","shell.execute_reply.started":"2023-06-06T05:29:09.310112Z","shell.execute_reply":"2023-06-06T05:29:09.940500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv')\ntest['EJ'].replace(['A', 'B'], [1, 0], inplace=True)\n\ntest_ej = np.array(pd.get_dummies(test['EJ']))\n\nx_test_scaled = scaler.transform(test[x_numerical_columns])\n\nX_test = np.append(x_test_scaled, test_ej, axis=1)\nd_test = xgb.DMatrix(X_test)\n\npreds = pd.DataFrame(index=range(test.shape[0]))\n\nfor i in range(0, 10):\n\n    X_train, X_val, y_train, y_val = train_test_split(\n        X, y, test_size=0.05, shuffle=True)\n    sampler_model = RandomOverSampler()\n    X_re, y_re = sampler_model.fit_resample(X_train, y_train)\n\n    dtrain = xgb.DMatrix(X_re, y_re)\n    dval = xgb.DMatrix(X_val, y_val)\n\n    model = xgb.train(params=best_params,\n                      dtrain=dtrain,\n                      obj=balancedlogloss,\n                      evals=[(dtrain, 'dtrain'), (dval, 'dval')],\n                      feval=balancedlogloss_eval,\n                      verbose_eval=5,\n                      early_stopping_rounds=5\n                      )\n\n    p = expit(model.predict(d_test))\n    p = pd.Series(p)\n\n    preds = pd.concat([preds, p], axis=1)\n    print('\\n')\n\npred_1 = np.mean(preds, axis=1)\npred_0 = 1 - pred_1\n\n# pred_0\n\nsubmission = pd.DataFrame(index=test.index, columns=sample_submission.columns)\nsubmission['Id'] = test['Id']\nsubmission['class_0'] = pred_0\nsubmission['class_1'] = pred_1\n\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T05:28:25.525003Z","iopub.execute_input":"2023-06-06T05:28:25.525778Z","iopub.status.idle":"2023-06-06T05:28:26.215562Z","shell.execute_reply.started":"2023-06-06T05:28:25.525738Z","shell.execute_reply":"2023-06-06T05:28:26.214628Z"},"trusted":true},"execution_count":null,"outputs":[]}]}